{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 定义网络"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5, stride=1)\n",
    "        self.fc1 = nn.Linear(in_features=20 * 12 * 12, out_features=100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2, 2)  # kernel_size=2, stride=2，pooling之后的大小除以2\n",
    "        x = x.view(-1, 20 * 12 * 12)  # 展开为行向量\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)  # 按行进行log(softmax(x))\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 数据加载"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def data_loader(batch_size, batch_size_test, use_cuda=False):\n",
    "    \"\"\"\n",
    "    数据加载器\n",
    "\n",
    "    :param batch_size: 训练集批次大小\n",
    "    :param batch_size_test:  测试集批次大小\n",
    "    :param use_cuda: 是否使用GPU\n",
    "    :return: 训练集和测试集\n",
    "    \"\"\"\n",
    "\n",
    "    # GPU训练需要的参数\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(root='./files/',\n",
    "                       train=True,\n",
    "                       download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           # 把[0,255]的(H,W,C)的图片转换为[0,1]的(channel,height,width)的图片\n",
    "                           transforms.ToTensor(),\n",
    "                           # z-score标准化为标准正态分布\n",
    "                           # 这两个数分别是MNIST的均值和标准差\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        **kwargs)\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(root='./files/',\n",
    "                       train=False,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size_test,\n",
    "        shuffle=True,\n",
    "        **kwargs)\n",
    "\n",
    "    return train_loader, test_loader"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 训练脚本"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def train(log_interval, network, device, train_loader, train_losses, optimizer, epoch):\n",
    "    \"\"\"\n",
    "    训练过程\n",
    "\n",
    "    :param log_interval: 计算训练效果的间隔\n",
    "    :param network: 网络模型\n",
    "    :param device: 使用的设备 CPU or GPU\n",
    "    :param train_loader: 训练集\n",
    "    :param train_losses: 记录损失变化\n",
    "    :param optimizer: 优化器\n",
    "    :param epoch: 当前的迭代次数\n",
    "    :return: null\n",
    "    \"\"\"\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 每个batch重新计算梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向计算出预测输出\n",
    "        output = network(data)\n",
    "        # 对数似然代价\n",
    "        loss = F.nll_loss(output, target)\n",
    "        # 求梯度\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "        # 每经过一个log_interval大小的间隔，记录一下训练效果\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                       100. * batch_idx / len(train_loader), loss.item()))\n",
    "            train_losses.append(loss.item())\n",
    "            train_counter.append(\n",
    "                (batch_idx * batch_size_train) + ((epoch - 1) * len(train_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 测试脚本"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def test(network, device, test_loader, test_losses):\n",
    "    \"\"\"\n",
    "    测试过程\n",
    "\n",
    "    :param network: 网络模型\n",
    "    :param device: 测试使用的设备\n",
    "    :param test_loader: 测试集\n",
    "    :param test_losses: 记录损失变化\n",
    "    :return: null\n",
    "    \"\"\"\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # 预测时不需要反向传播\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            predict = output.argmax(dim=1, keepdim=True)\n",
    "            correct += predict.eq(target.view_as(predict)).sum().item()\n",
    "\n",
    "    # 上面test_loss得到的是累加和，这里求得均值\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### MAIN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda...\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.298396\n",
      "Train Epoch: 1 [640/60000 (1%)]\tLoss: 1.998022\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 1.627732\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 1.216517\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 0.802180\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.747045\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 0.575385\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 0.526559\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 0.469119\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 0.361926\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.521784\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 0.343188\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 0.539871\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 0.314487\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 0.217913\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.441859\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 0.431089\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 0.388443\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 0.477139\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 0.501813\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.430132\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 0.227305\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 0.304199\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 0.562084\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 0.309096\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.406570\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 0.440904\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 0.369682\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 0.295525\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 0.117282\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.212880\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 0.278652\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 0.208848\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 0.154767\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 0.231218\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.184670\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 0.368313\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 0.444219\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 0.126164\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 0.446300\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.166513\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 0.114742\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 0.120203\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 0.244726\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 0.245504\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.203595\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 0.142510\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 0.277858\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 0.172410\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 0.250881\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.185677\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 0.302044\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 0.160520\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 0.195113\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 0.225303\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.239254\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 0.102100\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 0.302356\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 0.173543\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 0.244974\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.171168\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 0.197731\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 0.298906\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 0.173770\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 0.203847\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.133906\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 0.120478\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 0.101478\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 0.208358\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 0.130502\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.086513\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 0.176367\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 0.178749\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 0.110867\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 0.242652\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.097696\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 0.195818\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 0.343256\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 0.202162\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 0.068026\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.236014\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 0.062531\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 0.132735\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 0.124956\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 0.157893\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.196637\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 0.192645\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 0.163640\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 0.170503\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 0.163732\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.118756\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 0.083985\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 0.125079\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 0.155239\n",
      "\n",
      "Test set: Average loss: 0.1327, Accuracy: 9629/10000 (96.29%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.106198\n",
      "Train Epoch: 2 [640/60000 (1%)]\tLoss: 0.097391\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 0.273512\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 0.144135\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 0.197500\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.077016\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 0.101857\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 0.054775\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 0.189937\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 0.250775\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.171139\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 0.159146\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 0.189004\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 0.063806\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 0.257558\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.126956\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 0.070843\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 0.033450\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 0.165228\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 0.075600\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.079426\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 0.140752\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 0.214517\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 0.112719\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 0.099064\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.031035\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 0.107536\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 0.080108\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 0.142529\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 0.081889\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.103509\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 0.108196\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 0.086583\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 0.197189\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 0.193941\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.037601\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 0.087591\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 0.183078\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 0.152706\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 0.076138\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.080334\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 0.139349\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 0.067991\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 0.081820\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 0.084552\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.212060\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 0.212924\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 0.192385\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 0.144617\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 0.372799\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.171815\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 0.246576\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 0.098863\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 0.092085\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 0.079017\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.049518\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 0.069036\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 0.058885\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 0.196586\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 0.057780\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.073648\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 0.159154\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 0.061895\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 0.078275\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 0.082455\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.052414\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 0.036074\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 0.057608\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 0.129121\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 0.112681\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.141500\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 0.117553\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 0.058571\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 0.051695\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 0.077222\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.121252\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 0.094897\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 0.092663\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 0.220363\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 0.081767\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.068130\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 0.050225\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 0.100881\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 0.103712\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 0.092044\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.034230\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 0.151353\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 0.091214\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 0.077396\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 0.032301\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.064745\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 0.038420\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 0.108294\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 0.171856\n",
      "\n",
      "Test set: Average loss: 0.0802, Accuracy: 9747/10000 (97.47%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.099372\n",
      "Train Epoch: 3 [640/60000 (1%)]\tLoss: 0.012902\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 0.062954\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 0.052383\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 0.081556\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.032148\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 0.096773\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 0.027594\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 0.120958\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 0.072351\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.204420\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 0.040360\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 0.032916\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 0.250733\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 0.039877\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.059794\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 0.011729\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 0.177732\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 0.024596\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 0.068621\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.172225\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 0.052301\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 0.046865\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 0.074419\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 0.042790\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.035962\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 0.109684\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 0.125437\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 0.079055\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 0.013007\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.055862\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 0.024942\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 0.031092\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 0.124733\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 0.045584\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.106042\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 0.064904\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 0.063423\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 0.115662\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 0.061192\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.175102\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 0.167300\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 0.016917\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 0.050374\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 0.022284\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.040271\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 0.158212\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 0.098962\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 0.079775\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 0.039504\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.059178\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 0.057673\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 0.117512\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 0.039983\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 0.011060\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.089662\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 0.019167\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 0.044584\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 0.102309\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 0.100420\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.040734\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 0.052010\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 0.112785\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 0.095221\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 0.078778\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.049318\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 0.021613\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 0.051214\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 0.064188\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 0.027065\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.053787\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 0.069672\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 0.085669\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 0.023981\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 0.164598\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.018955\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 0.110616\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 0.077671\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 0.039613\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 0.022365\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.045508\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 0.078948\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 0.068391\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 0.038661\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 0.087437\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.112647\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 0.018830\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 0.039468\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 0.072741\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 0.073341\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.015913\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 0.107983\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 0.044962\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 0.013063\n",
      "\n",
      "Test set: Average loss: 0.0583, Accuracy: 9817/10000 (98.17%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "\n",
    "random_seed = 1\n",
    "\n",
    "# 启用英伟达cuDNN加速框架和CUDA\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.manual_seed(random_seed)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"using {}...\".format(\"cuda\" if use_cuda else \"cpu\"))\n",
    "\n",
    "# 加载数据\n",
    "train_loader, test_loader = data_loader(batch_size=batch_size_train, batch_size_test=batch_size_test, use_cuda=use_cuda)\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i * len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "\n",
    "network = Network().to(device)\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(log_interval, network, device, train_loader, train_losses, optimizer, epoch)\n",
    "    test(network, device, test_loader, test_losses)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 评估"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Text(0, 0.5, 'negative log likelihood loss')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAABAsElEQVR4nO2dd5xU5fX/34e2S1GQolKUomADBCWiKIol9hK7BhXUxBrR+FVjjYZooskvatREJEaJihGjYENjIaKoIAIiRVQQQUBE6tLLLuf3x7nXe2d2Znd22ZndZc779ZrXbc+999w7M8/nOedpoqo4juM4+Uud6jbAcRzHqV5cCBzHcfIcFwLHcZw8x4XAcRwnz3EhcBzHyXPqVbcBFaVly5baoUOH6jbDcRynVjF58uRlqtoq1bFaJwQdOnRg0qRJ1W2G4zhOrUJE5qc75qEhx3GcPMeFwHEcJ89xIXAcx8lzal0dgeM42xdbtmxh4cKFbNy4sbpN2S4oLCykXbt21K9fP+NzXAgcx6lWFi5cyA477ECHDh0Qkeo2p1ajqixfvpyFCxfSsWPHjM/z0JDjONXKxo0badGihYtAFSAitGjRosLelQuB4zjVjotA1VGZd5k3QjBjBtxxByxbVt2WOI7j1CzyRgi+/BLuvhu++666LXEcpyaxfPlyevToQY8ePdh1111p27btj9ubN28u89xJkyYxaNCgCt2vQ4cOLKthJdK8qSxu1MiW69ZVrx2O49QsWrRowdSpUwG46667aNKkCTfccMOPx4uLi6lXL3VW2atXL3r16pULM7NK3ngEjRvbcv366rXDcZyaz8CBA7niiivo3bs3N910ExMnTuSQQw6hZ8+e9OnThy+//BKAsWPHcvLJJwMmIpdccgn9+vWjU6dOPPTQQxnfb968eRx11FF0796do48+mm+//RaA//znP3Tt2pX999+fww8/HICZM2dy0EEH0aNHD7p3787s2bO3+XnzxiMIhcA9AsepuVx3HQSF8yqjRw948MGKn7dw4UI++ugj6taty+rVqxk3bhz16tXjnXfe4dZbb+XFF18sdc4XX3zBu+++y5o1a9hrr7248sorM2rPf8011zBgwAAGDBjAE088waBBg3jppZcYPHgwb775Jm3btmXVqlUADBkyhGuvvZb+/fuzefNmSkpKKv5wSeSNEHhoyHGcinD22WdTt25dAIqKihgwYACzZ89GRNiyZUvKc0466SQKCgooKChg5513ZsmSJbRr167ce40fP56RI0cCcOGFF3LTTTcBcOihhzJw4EDOOecczjjjDAAOOeQQ7rnnHhYuXMgZZ5xB586dt/lZ80YIPDTkODWfypTcs0XjMNMA7rjjDo488khGjRrFvHnz6NevX8pzCgoKflyvW7cuxcXF22TDkCFD+Pjjjxk9ejQHHnggkydP5uc//zm9e/dm9OjRnHjiiTz22GMcddRR23SfvKsjcI/AcZyKUlRURNu2bQEYNmxYlV+/T58+PPfccwAMHz6cvn37AvD111/Tu3dvBg8eTKtWrViwYAFz586lU6dODBo0iNNOO41p06Zt8/3zRgg8NOQ4TmW56aabuOWWW+jZs+c2l/IBunfvTrt27WjXrh3XX389Dz/8ME8++STdu3fn6aef5q9//SsAN954I926daNr16706dOH/fffn+eff56uXbvSo0cPZsyYwUUXXbTN9oiqbvNFckmvXr20MhPTqELdunDbbfD732fBMMdxKsWsWbPYZ599qtuM7YpU71REJqtqyraueeMRiFh4yD0Cx3GcRPJGCMDCQy4EjuM4ieSVEDRu7K2GHMdxksk7IXCPwHEcJ5G8EgIPDTmO45Qmr4TAQ0OO4zilyZuexWBCsGhRdVvhOE5NYvny5Rx99NEAfP/999StW5dWrVoBMHHiRBo0aFDm+WPHjqVBgwb06dOn1LFhw4YxadIkHnnkkao3vArJKyHw0JDjOMmUNwx1eYwdO5YmTZqkFILagoeGHMepXQwfDh06QJ06thw+vMpvMXnyZI444ggOPPBAjjvuOBYvXgzAQw89xL777kv37t0577zzmDdvHkOGDOGBBx6gR48ejBs3LqPr33///XTt2pWuXbvyYDDA0rp16zjppJPYf//96dq1KyNGjADg5ptv/vGeFRGoipBXHoG3GnKcWs7w4XDZZVGJbv582wbo379KbqGqXHPNNbz88su0atWKESNGcNttt/HEE09w77338s0331BQUMCqVato1qwZV1xxRYW8iMmTJ/Pkk0/y8ccfo6r07t2bI444grlz59KmTRtGjx4N2PhGy5cvZ9SoUXzxxReIyI9DUVc1eeUReGjIcWo5t91W2q1fv972VxGbNm1ixowZ/PSnP6VHjx7cfffdLFy4ELAxgvr3788zzzyTdtay8vjggw84/fTTady4MU2aNOGMM85g3LhxdOvWjbfffpvf/OY3jBs3jqZNm9K0aVMKCwu59NJLGTlyJI3CQdOqmLwSgsaNYfNmqIIxoxzHqQ6Cmbsy3l8JVJX99tuPqVOnMnXqVKZPn85bb70FwOjRo7n66quZMmUKP/nJT6pkALqQLl26MGXKFLp168btt9/O4MGDqVevHhMnTuSss87itdde4/jjj6+y+8XJOyEArydwnFrL7rtXbH8lKCgoYOnSpYwfPx6ALVu2MHPmTLZu3cqCBQs48sgjue+++ygqKmLt2rXssMMOrFmzJuPr9+3bl5deeon169ezbt06Ro0aRd++ffnuu+9o1KgRF1xwATfeeCNTpkxh7dq1FBUVceKJJ/LAAw/w2WefVdlzxsmrOoL4UNQ77li9tjiOUwnuuSexjgDsj33PPVV2izp16vDCCy8waNAgioqKKC4u5rrrrqNLly5ccMEFFBUVoaoMGjSIZs2accopp3DWWWfx8ssv8/DDD/84l0DIsGHDeOmll37cnjBhAgMHDuSggw4C4Be/+AU9e/bkzTff5MYbb6ROnTrUr1+fRx99lDVr1nDaaaexceNGVJX777+/yp4zTtaGoRaR3YCngF0ABYaq6l+T0gjwV+BEYD0wUFWnlHXdyg5DDfDUUzBgAMyZA3vsUalLOI5TxVR4GOrhw61O4NtvzRO4554qqyjeXqjoMNTZ9AiKgf9T1SkisgMwWUTeVtXPY2lOADoHn97Ao8EyK/gsZY6zHdC/v2f8VUzW6ghUdXFYulfVNcAsoG1SstOAp9SYADQTkdbZsslnKXMcxylNTiqLRaQD0BP4OOlQW2BBbHshpcUCEblMRCaJyKSlS5dW2o5QCLyy2HFqFrVtpsSaTGXeZdaFQESaAC8C16nq6spcQ1WHqmovVe0VjgFSGRo2tOXGjZW+hOM4VUxhYSHLly93MagCVJXly5dTWFhYofOy2mpIROpjIjBcVUemSLII2C223S7YlxVCIdiwIVt3cBynorRr146FCxeyLd6+E1FYWEi7du0qdE7WhCBoEfRPYJaqpmvz9ArwKxF5DqskLlLVxdmyKRRJFwLHqTnUr1+fjh07VrcZeU02PYJDgQuB6SIyNdh3K7A7gKoOAV7Hmo7OwZqPXpxFezw05DiOk4KsCYGqfgBIOWkUuDpbNiTjoSHHcZzS5NUQEx4achzHKU1eCYGHhhzHcUpTrhCIyJ9EZEcRqS8iY0RkqYhckAvjqpo6daBBA/cIHMdx4mTiERwbtP8/GZgH7AncmE2jsklhoQuB4zhOnEyEIKxQPgn4j6oWZdGerNOwoYeGHMdx4mTSaug1EfkC2ABcKSKtgFqblTZs6B6B4zhOnHI9AlW9GegD9FLVLcA6bLC4WomHhhzHcRLJpLL4bGCLqpaIyO3AM0CbrFuWJTw05DiOk0gmdQR3qOoaETkMOAYbNuLR7JqVPTw05DiOk0gmQlASLE/CZhkbDTTInknZpbDQPQLHcZw4mQjBIhF5DDgXeF1ECjI8r0biHoHjOE4imWTo5wBvAsep6iqgObW4H4ELgeM4TiKZtBpaD3wNHCcivwJ2VtW3sm5ZlvDQkOM4TiKZtBq6FhgO7Bx8nhGRa7JtWLZwj8BxHCeRTDqUXQr0VtV1ACJyHzAeeDibhmULFwLHcZxEMqkjEKKWQwTrZc4zUJPx0JDjOE4imXgETwIfi8ioYPtnWF+CWknDhrBpE2zdaqOROo7j5DvlCoGq3i8iY4HDgl0Xq+qnWbUqi8TnJGjUqHptcRzHqQmkFQIRaR7bnBd8fjymqiuyZ1b2CGcpcyFwHMcxyvIIJgNKVB+gwVKC9U5ZtCtr+LzFjuM4iaQVAlXtmEtDcoULgeM4TiJ5V10aDw05juM4eSgE7hE4juMk4kLgOI6T52TaaqgU20OrIcdxHCfzVkO7AyuD9WbAt0CtrEx2j8BxHCeRtKEhVe2oqp2Ad4BTVLWlqrYATgZq7eijLgSO4ziJZFJHcLCqvh5uqOob2GT2tZKCAltu2lS9djiO49QUMhlr6LvYpPUA/YHvsmdSdvE6AsdxnEQy8QjOB1oBo4LPzsG+WkkoBO4ROI7jGJkMOrcCuFZEdrBNXZt9s7KHewSO4ziJZDJDWTcR+RSYAcwUkcki0jX7pmWHsI7AhcBxHMfIJDT0GHC9qrZX1fbA/wFDs2tW9qhbF+rVcyFwHMcJyUQIGqvqu+GGqo4FGmfNohzgs5Q5juNEZCIEc0XkDhHpEHxuB+aWd5KIPCEiP4jIjDTH+4lIkYhMDT6/rajxlaWw0CuLHcdxQjIRgkuwVkMjg0+rYF95DAOOLyfNOFXtEXwGZ3DNKqGgwD0Cx3GckExaDa0EBlW01ZCqvi8iHbbRvqzgoSHHcZyI6m41dIiIfCYib4jIfmXYcJmITBKRSUuXLt3mm7oQOI7jRFRnq6EpQHtV3R94GHgpXUJVHaqqvVS1V6tWrbb5xl5H4DiOE1FtrYZUdXUYZgrGMqovIi239bqZ4HUEjuM4EVlrNVQeIrKriEiwflBgy/JtvW4meGjIcRwnIpNB5y4Bfoe1GAIYRwathkTk30A/oKWILATuBOoDqOoQ4CzgShEpBjYA56mqVvQBKkNhIRQV5eJOjuM4NZ+MWw1V9MKqWubAdKr6CPBIRa9bFXgdgeM4TkS5QiAiXYAbgA7x9Kp6VPbMyi4eGnIcx4nIJDT0H2AI8DhQkl1zcoNXFjuO40RkIgTFqvpo1i3JIe4ROI7jRKQVAhFpHqy+KiJXYZPS/BhZD+YpqJW4EDiO40SU5RFMBhSQYPvG2DEFOmXLqGzjlcWO4zgRaYVAVTvm0pBcUlAAW7ZASYnNT+A4jpPPlBUaOkpV/yciZ6Q6rqojU+2vDcTnLW7UqHptcRzHqW7KCg0dAfwPOCXFMSXqYFbriM9b7ELgOE6+U1Zo6M5geXHuzMkNcY/AcRwn3ykrNHR9WSeq6v1Vb05u8AnsHcdxIsoKDe2QMytyTDw05DiOk++UFRr6XS4NySUuBI7jOBGZzFDWRUTGhJPQi0j3YCjqWosLgeM4TkQm8xH8A7gF2AKgqtOA87JpVLYJ6wi8sthxHCczIWikqhOT9hVnw5hc4R6B4zhORCZCsExE9sD6DiAiZwGLs2pVlnEhcBzHichk9NGrscnq9xaRRcA3QP+sWpVlXAgcx3EiMhGCnVT1GBFpDNRR1TUicjIwP8u2ZQ3vUOY4jhORUWWxiHRV1XWBCJwH3JFtw7KJdyhzHMeJyMQjOAt4QUR+DvQFLgKOzapVWcZDQ47jOBGZTF4/N/ACXgK+BY5V1Q3ZNiybuBA4juNElDXW0HSClkIBzYG6wMcigqp2z7Zx2cL7ETiO40SU5RGcnDMrckzdulCvnnsEjuM4ULYQrFTV1bG5i7crfN5ix3EcoywheBbzCpLnLoZaPmcxuBA4juOElDX66MnBcrucu9iFwHEcxyirsviAsk5U1SlVb07uKCjwymLHcRwoOzT0lzKOKXBUFduSU9wjcBzHMcoKDR2ZS0NyjQuB4ziOkckQE9slLgSO4zhG3gqB1xE4juMYeSsE7hE4juMY5Y41lKb1UBEwX1Vr7UxlLgSO4zhGJqOP/h04AJiGdSrrCswEmorIlar6VhbtyxouBI7jOEYmoaHvgJ6q2ktVDwR6AnOBnwJ/SneSiDwhIj+IyIw0x0VEHhKROSIyrbx+C1WNC4HjOI6RiRB0UdWZ4Yaqfg7srapzyzlvGHB8GcdPADoHn8uARzOwpcrwymLHcRwjk9DQTBF5FHgu2D4X+FxECoAt6U5S1fdFpEMZ1z0NeEpVFZggIs1EpLWqLs7Q9m3CPQLHcRwjE49gIDAHuC74zA32bQG2pdNZW2BBbHthsK8UInKZiEwSkUlLly7dhltGuBA4juMYmcxQtkFEHgbewoaW+FJVQ09gbTaNi9kwFBgK0KtXLy0neUYUFkJxMZSU2PwEjuM4+UomzUf7Af8C5mGthnYTkQGq+v423nsRsFtsu12wLyfEZylr1ChXd3Ucx6l5ZBIa+gs2T/ERqno4cBzwQBXc+xXgoqD10MFAUa7qB8DnLXYcxwnJpLK4vqp+GW6o6lciUr+8k0Tk30A/oKWILATuBOoH1xgCvA6ciNU/rAcurrD124ALgeM4jpGJEEwSkceBZ4Lt/sCk8k5S1fPLOa7A1RncPyu4EDiO4xiZCMGVWIY9KNgeh/U2rtXE6wgcx3HymUxaDW0C7g8+2w3uETiO4xhlTVU5HWsumhJV7Z4Vi3KEC4HjOI5Rlkdwcs6sqAZcCBzHcYyypqqcn0tDck1YR+BC4DhOvpPXE9OAVxY7juPkvRC4R+A4Tr6TkRCISEMR2SvbxuQSFwLHcRyjXCEQkVOAqcB/g+0eIvJKlu3KOi4EjuM4RiYewV3AQcAqAFWdCnTMmkU5wjuUOY7jGJkIwRZVLUraVyVDQVcn7hE4juMYmc5Q9nOgroh0xoaa+Ci7ZmWfggKoUwdWrapuSxzHcaqXTDyCa4D9gE3As0ARNlNZraZuXejeHSaVO3ye4zjO9k0mHsHeqnobcFu2jck1ffrAU0/5LGWO4+Q3GU1MIyKzROT3ItI16xblkEMPhbVrYcaM6rbEcRyn+ihXCFT1SGyS+qXAYyIyXURuz7plOaBPH1t+VOtrPBzHcSpPRh3KVPV7VX0IuALrU/DbbBqVK9q3h+bN4bPPqtsSx3Gc6iOTDmX7iMhdwbDUD2Mthtpl3bIcIAI77wzLl1e3JY7jONVHJpXFTwAjgONU9bss25NzWrRwIXAcJ7/JZIayQ3JhSHXRogXM364H3HYcxymbsmYoe15Vz0kxU5lgc8/X6hnKQpo3hylTqtsKx3Gc6qMsj+DaYLldz1TmoSHHcfKdtJXFqro4WL1KVefHP8BVuTEv+7RoARs22MdxHCcfyaT56E9T7Duhqg2pLpo3t+WKFdVrh+M4TnVRVh3BlVjJv5OITIsd2gH4MNuG5YoWLWy5fDm0bVu9tjiO41QHZdURPAu8AfwRuDm2f42qbjfl57gQOI7j5CNphSCYg6AIOB9ARHYGCoEmItJEVb/NjYnZxUNDjuPkOxlNVSkis4FvgPeAeZinsF3gHoHjOPlOJpXFdwMHA1+pakfgaGBCVq3KIS4EjuPkO5lOVbkcqCMidVT1XaBXlu3KGQ0b2rSVHhpyHCdfyWSsoVUi0gR4HxguIj8A67JrVm7xTmWO4+QzmXgEpwEbgF8D/wW+Bk7JplG5pn17mDVr26+zahW8sd3UnjiOky9kMjHNOlUtUdViVf2Xqj4UhIq2G/r1g08+gTVrtu06w4bBSSeZIDiO49QWMmk1tEZEVid9FojIKBHplAsjs81RR9m8xePGJe5fuxaGDgXV1Ocls3KlpS0qqnobHcdxskUmoaEHgRuBttiENDdgnc2ew+YqqPX06QMNGsC77ybuf+kluPxy+OKLzK6zdm3i0nEcpzaQiRCcqqqPqeoaVV2tqkOxSWpGADuVdaKIHC8iX4rIHBG5OcXxgSKyVESmBp9fVPI5tomGDeHgg+G992z7+efhiCOiCuRMQz1haGlbQ0yO4zi5JBMhWC8i54hIneBzDrAxOJY2aCIidYG/YQPU7QucLyL7pkg6QlV7BJ/HK/oAVcUhh8DUqbBxI3zwAbz/PnwXzMeWLtSzfLmFg0JCT8CFwHGc2kQmQtAfuBD4AVgSrF8gIg2BX5Vx3kHAHFWdq6qbsVDSadtob9Y4+GDYsgU+/RSWLbN9c+facvXq0umLi+Gww+CCC6J9oQB4aMhxnNpEJlNVziV9c9EPyji1LbAgtr0Q6J0i3ZkicjjwFfBrVV2QnEBELgMuA9h9993LM7lS9A4smzAhEoKvv7ZlKiF49lmrO4j3P3CPwHGc2kgmrYa6iMgYEZkRbHcXkdur6P6vAh2CaS/fBv6VKpGqDlXVXqraq1WrVlV060Rat7b+BHEhKMsjeOABWy5dCkuW2Lp7BI7j1EYyCQ39A7gF2AKgqtOA8zI4bxGwW2y7XbDvR1R1uapuCjYfBw7M4LpZo1cvqycIhSCsG0iuIygpgc8/t/QA06fb0j0Cx3FqI5kIQSNVnZi0rziD8z4BOotIRxFpgInHK/EEItI6tnkqUAX9eytPx47w7bdWyo8TegQlJbZcsAA2b4bTT7ftGTNsuS1CoApffWXrr77qU2c6jpM7MhGCZSKyB0ELIRE5C1hc9imgqsVYZfKbWAb/vKrOFJHBInJqkGyQiMwUkc+AQcDASjxDlbH77tZqaOPGxP2rV1vmvtNO0L9/1K+gTx9o1SryCOKhoW++gU6dYNo0MmLoUNhrLxgxAk49FV54oWqeyXEcpzwyGXTuamAosLeILMLmJbig7FMMVX0deD1p329j67dgYacaQbp66NWrYfFiy+iffRYmTbL9nTtDt24wc6aV6OMewRNPmBj873/QvXv5937xRVuGFdQ+TIXjOLki01ZDx4hIY6COqm63EfB0QlBUlFhh/NVX1gmtdWv7TJhgoZytW+346tUmABB5C+Uxb54tN2+25brtanxXx3FqMuUKgYgUAGcCHYB6IgKAqg7OqmXVwG67pd6/enUkBEceaUNR7LEH1KkDTZta6T3eUujdd61Zaf36Uf1Becyfb8uwotpbHjmOkysyqSN4GesIVozNQxB+tjtatLCSPljsP2T16qjl0M9/bss997Rls2YmBPEK4rBvwXHHWdgo9BTSsXVr5AmEFdXuETiOkysyqSNop6rHZ92SGoCIhYe+/BK6dLFMuUWL0h5B167Qt69tN2tmrYnCvgQhderACSfAa69Zab9jx/T3DcNC4B7B9kA4Wm3gPDtOjScTj+AjEemWdUtqCLvvbpl4p2CA7fbtE+sImjWzuP/110fbAAsX2jL0JHbbDXr2tPXywkOffx6th0LgHkHt5Zhj4OZSQyw6Ts0lEyE4DJgcjCI6TUSmi0iGjSJrH507Q5s2UYbevr2VzsPB5XbcMTF9KAQLgoExWgc9Izp2hP32s/XyhGBBbFAN9whqP7NmWUjQcWoLmQjBCUBn4FhszKGT2c6mqowzeDC8/TY0b27bYUuiRYus/qB+/cT0TZvaMvQI4kKw4452fnlCEB/BtLZ4BP/+d6KAORGrV3vzX6d2kclUlfNTfXJhXHXQogXsvbcNS92rl3kIYBl9sjcApUNDcSEAq08oTwhWrIBGjUxUwkrjmuwRbNhgleZDhlS3JTWPkhITcRcCpzaRiUeQlxx1lM1jHIaIFiyonBB062Y9kbdsSX+vlSut13KjRtG+muwRhC2bFpfbvzz/CFuPuRA4tQkXgnIIQz/ffhutx8nEI9i8GebMSX+PVEJQkz2CH36wZXJLKSdqVOBC4NQmXAjKoV07WxYVpfYI4nUE9evbFJd9+kTDSnTtasuywkMrVlidRGU9glWrLJz1ySelj/3hD3DWWYn71qyBK6+sfGblQpCeUAjWrbPJixynNuBCUA4dOkTrqYSgoAAKC229c2cTgA8/hB12sH177WXLcGTRVGyrR/D559b3YcKE0sfGj4+GuwgZO9bi++EczRUlDA25EJQmPhRJuilOHaem4UJQDo0bw84723oqIYAoPLTPPqWPNWxo11ixwravugpuvTUxTSqPYOPGaNjrZMaMgZNOio6HYalUGfOqVSY08RFVww5s4ZzMFSXuEWjaWasrxuTJJqC1nbgQeHjIqS24EGRAGO9PVUcA0bAU++6b+njz5pbZq1qzy+QhplN5BJA+PPTWW/D661FGviiY7ifMoOOEmdH330f7wnGNtlUItmxJbPq6LdxyC/yqrBmwU1BcXHYlfHXgQuDURlwIMiAUgnQeQZgxlicE8+db5jBnTpTJb95s682bm+cQJ0yjahluGHMOS/6zZtmUmWHGns4jgMQWPlXlEaS7Z2VYujQStGS2boW//a10xnrJJXDuuVVz/6oiLgSLF9fsSv+qZvVqCzlWlZfo5A4XggwIh5tIJwRhhp0qNASREHz6qW2rRj1PwxJ1Ko8gzETOOceuccIJth2W7h94wIa6ePZZ245n0CNHwkcfRZnnfffZc2zZEglBRZp/LlkCP/2pLeMzuH3/vW2HHeEqy4oVdp1UJfxPPjFvIXzOkC++yHzin1wRF4Jzz7VJhvKFl16yRghfflndljgVxYUgA8oLDYV06ZJ6fygEU6dG+6ZNg5dfhuOD4fziQhD2Xg4F5uOPbTlmjGWWoRCElb3JlbfPPgtnngnnnx+Jyauv2kQ5s2dXLjQ0fjy88w5MnGiCE1aiL1kCF10EF1+c+bVSEdahpPIwwtZQs5ImMl250sSsJpVA4xXE69fnV6YYFmqqKlzo5A4XggwoLzR01102rlBYV5BM3CPYe29o0sSEYMSISBzilcVhJ7a1ay0s8v33VhpXhTfeiDLL5HmNlyyxEunll9t2vII4HAp74sSo9F4RIQjFZ8kSE4Ju3aLtefMicakMmzdHghWvywgJhSCcIjRk1SrLbMsKv4wZU7k5pCvCF19YS6zNm+39160bHfvhh9wK1ZtvwtFHp29okE1Cb8hbS9U+XAgyoHdvOPvsaOjpZO68s+x+AqEQTJtmI5J26waffZY46mjcIwhbKa1bZ3MbbNkCJ59sndVefjl1pXCDBpYpPvaYZYzduqVON3q0Lffe2zyJf/0rMaxzzz3wu9+VPi8MI4VCsNde5rl8/73ZGJboK0O8BJkqXJVKCMJ6k3TngNU5HHMMPP545W0rjzlzLCR45JHWGmz1athll+h4cXFuK43feceaC6f67rPB55/bUOsQCYBXktc+XAgyoEkTeP75qHNZRWne3EqL8+dbX4NevWze43jGls4jCEvtbdtaGOm11xInugm9kLCEftddcOCBcEqaYQHfesuWhxxiy4EDE8cMeu45E4dkwpL611/Dpk2W2e28s+1fsaK0EEydas95002Jnkkqwol8wOoywroQsNL8F19YWG7hQttevtzEKyz1phOCcJrQcB7o8li5Evbf35rmZnpO2GO8Z0948EFrAhs2Jw6J16mEbNxo32c8XFgVxAU7F9x3XxQWDIXAPYLahwtBDghHMgULMx12mJXeN22K9qfzCEIhaNPGPJNwULo2bWwZZvgHHGDL9estNLTrrtG1w85tHTtaibVNG8vsQuIVrt9+a6GeDRus1D1tmtVRhEIwZUp0/112sTqHkhJLHw9VPfaYZXJ//nP5JfK4iHz4Ifz3v5F4zJhhdpx5ZmRry5aJlbCpwknhuZA48U9ZfPaZXf/1163iE+DRR6P1VIQZ79Ch1rnwyy9LhxBTlc5nz7YwzpgxmdmWKbkWgu++M2EuKUkdGvruu5rXxNcpjQtBDogLQadOcOih0fa//mWhmLhHEArB2rXRH7t1aythhxx0kC2vu85KZRddFB07++xEIdh7b4tbh0NNXH99NLw2RCXncAIeVcvQHn7YSsiHHBIJQJi2Y0e7R3zc/TBDLymBUaPg9NNNvP76V/NUkns4J58XJxTA8PmPOcaWd95py3gv6jCNamKrndC2TOsvUs0LcdVV9hzpMrPw3vvtB4cfbuuZCEGYUVd1hr2tQrBqFVx6aeahvu+/j8J0yR7Bpk322xs61LYffTS1t7ktrFxp/6kBA6wQVFOojjqabcGFIAckewRt29qENwA/+xn89rc2rWEoBGEmvnRplCG2bm3hnwYNbPvKK+Hqq6PwS3wojGbNEuPUt91m4Z9zzzUP4rLLzIMYPBiuuMKGv9iwwbyBkFmzosxfNeq9HIalOna0e8TjwWGIZ/x4y4jOPBMGDbLwye9+Z5WYTz4ZpV/66AssbHcwK06z2EKTwii3DfsUhKX9vn2tn0aqEnSYZtQoe0+hHXGPIJMK21AImjWzdx/v0Pfqq6nPWbzY0jdsaM8HFr76+9+jupZUoaFkIXjmGfjgg/JtLI9tFYI334QnnsjcUwnf/fLlpYVg2TJ7F2H47IEHTAyqklmzrDXcU0/BP/+ZeGzq1KhOLJeMG2deeDpPtSbiQpADQiFo0CAK6RxzjNUXxEuPoRC0aGGD1X30kQlBixYWdmjQAHr0sDR9+sAjj0RNTdu0sZBQmHnHheDII+EXv7C6g1desR9p3bpwxx1mx9atVukXF4LPP7c/cBhyilNYaNeP3wOiUuTw4ZbmpJNMfIYNM7Hp0sV6VoeJTv9VG05Z9Cgr2AmAfTdP/fFaoQAuWWJTh7ZubR7FiSdaaChOmPnNnGmlwlmzomcqLEycYS5k06bSpd4FC+xd7767ZWLxkFJcwJLvHY44GwrBpEkm1OF0lak8gngrLFUTzD//OfU94iS3FEs+lqoneTKXXx55VsmEdRbffFO+LZs3R57TsmWlK4tDQV661J7x228r34kxHWEBBUpPlPT738MFF+S+efHUqfZdlDXicE3DhSAHhELQvn3UtPDBB63kECcUgkaNLMzw0Uf25wkzGrCwUsuWVoEdp04dK/WH8ySHXkWdOqXTxglHSf3ss0gImja1zHTOHLte2KEurGvo0ME8mGQh+OorC9n8+9/mDYSCM2CAid5JJ8H771tm/emNz/Lh1j5MozsLaUddijlk64d0rGdGxD2CVq3sOrvsYiW8q6+O7tmyZZTphYIwZ45lZOvXQ79+ti85PHTHHSaq8UxiwQKba7plS8u85s61/V26RBnkyJFw3HHReXEh2H9/W/7yl7Zs0MC8hfJCQ8uXm1CVlfmq2nO1aJE+vBLP/MvyCEaPLt05L6QiQhB/ruXLS9cRhCKxdKml3bTJ3le8scO2Emb+TZqUfs8LF5oozZ5ddffLhPDd56rlVlXgQpADQiEIM1SwH25yRposBGvXmqseehFg4Ybx48u/5447mhfRtKmJQTo6dbKM7Pe/t+vWr2/3njDBftB77hllcKFohP0q4vUQANdea/UJRUU2/EMyxx1nmcF778Gji38GwFbqMpZ+NGcFf+ImphXvR2FhVHL8/vvS7ykujPvsk5gWrMVP6BmdfrotkyuM33vPMpEws4dICFq1skwszAxPOskyldWrTeTeeisSzbgQ1KljldyPPBJdc+edyw8NhRnVN9+kLr1OmWK/lwsvtJLm7bcntsSaP9+uEW89lU4Iiost3Zw5qTt+hUIQfy+pWLDAPJ+QuEcQLuMeQSjExcXpPaSLL07tMYwebX1uUrFwoQ3N0rlz6fccegsTJ5b9LFVN+HwuBE4CDRta5r7HHmWnO+AAc9v79o36LBQXJw5dscMOljmXR1hiT27KmEzduhYuWrYMnn7aROeoo6IS+R57pBeC5Aw6zJz6949K4nEOP9xCNS+/DC/UOZu+vA/ApxxAc1bQgC00ad+Ctm0TPYJkwYkL48EHW8X2xo2REMyZY5lUgwZRq6rQTd+wwTKqzz6z7U8+iSYOSuURNG5sc0yAeUlhL+/p0y3TjgsBmPiKRNutWpXtEfzwQ9T7eO3axKa0IWPGmHczYYLVEy1caN9VSPi+Q7Fr3z69ECxZEpXI4xk52PsL32F5HkH//pHIhs8RduwrSwigdGa/ebM1ZBg2LBY6jHHPPaVH7J09235PU6ZYs+5kwS0ujp4lWQiWLLHfVCaj3S5danVsFRkzKi7yL76Y2DowFXPnWoOPVIWAZcvKP78qcCHIASJWkfmb35SdrmFDC+80b26Z3Z132g/k7rsrd99ddy1fCMAqnB9+2Nbnz09sx7/nnnDssZahhRlishC0aBHNyXDDDVbxmcoLadjQMubHH4eVW5sxqMFjtMDiB1uob2p5zz20bWsl9l//2jK9dEKw444WKtuyxYaxjoeGJk0y4dp1V1vec49l3uefb/Uv4Z/r73+3yvvOna2EHHoEK1daZtOpk7UIAsuQw1DE9OkWdti4MVEIktl5Z8v4kv/kYSZVUpLYAipVBhwOrdGvn5WM27SJhhdZvjyqS7rvPtvXo0eUGRUXWyuxvn3te4nH1JMnMgrF8eAGU5g/exNb23e0Cp8YixdH9TBx4nanCg3FhSB5cME33rBMuaAA3n679PPPnWvXv+8++y5KSmwE33HjLNTYrl1pwY0LXrIQvP++HX/33dL3GjnS6rWeeMK2n3vOJneKhyPLI3z3b7xhAve3v5WdvksXq09KruNQtULY4MGZ37vSqGqt+hx44IHqZMZjj6k+9FBmabduVb38ctW//c3WO3ZUBdWioijNt9+q1qun+s47tr18uaXp0kW1TRtbf+qpsu/z8suWrkED1dX/eE5HtfqlguqFjV9QfeYZVVU97zxLE35uvDHxGosW2f7dd1ddssTW//xn1cJCW2/a1D5XXGHp589X3Wkn1QsuUN111+i6u+xiy/BZQXXYMNVHHrH1nXdWPfVU1eJi1YICe05QFVE9/3zVGTNs+9//Tv+8gwdbmkMPVV2xItq/666qO+xgx/bd194rqI4YUfoavXqpHn10tP2zn6l27mzrzz4b2Ro+w623qtapY3a/+67ta93alj//uS3r1bNrbt0aXffec6coqN7HjQqq89lNtVGjH7+XrVvN7ssuS/x+WrRQPeYYW2/SxN69qup110VpBg609waqjz6a+h1deqlqw4aqGzZEx9asia4RPsOHH6qecEK0f8AA1euvN1NDPv7Yjh1wgN13woTo2I032rHzz7ftJ56w9KqqvXtH72fDBtWLLoru869/pf+eVVXXr1f94gvVDh2ia4Dqfvslvuc4EydG13/33cRj4W/7sMPKvm+mAJM0Tb5a7Rl7RT8uBLnhN7+xjC+ZZcui9a1bVevXVz3kENVu3ezX9OmnZV930ybVli1VTzwx2rdmjeratdF2/E8Oqn/5S+I1tmyxjG7//W27UyfL1EC1bdvovH/+Mzrn5JNV27WLju24o+rVV9v6a69ZXhfaP2JElO6GG+z8ffe17bp1VY86ytYbNYoypnQUF6s+/ri9p4MPNtuLi+06hx4a3eeww6KMa999bXvrVtWSEsscr7suuuYf/2hply9XvfBCy4i/+Ub1zjtNyEMh++QT1bvusozw++9Vd9stut+119ry7ruj657X6GXtwFwdw5EKqu9gD7qiXTft1cueA1SbNUv8frp1s+8gFDURs/vCC6M0XbvasTp1VO+4Q3X1atWZM+2+55xjYvzqq5Z2zJjIpmnTEu8VfiehiILq7bdH7yT8HY0cadtjx9r3vt9+ZpOq6hFH2LEePSKRP+MM1Y0brYCy5552fMIE1X32sd/jEUeoNm6sOmdO+u/5pz+176qgoLTNEydGaZ98UvXBB6PCV/Lv9ZtvVKdOVf3gA9vfuLFq8VPDVdu3t5fbvv2P4lwRXAicCrNli+q6deWna9vWMtkjjrDMbePG8s+ZOdNK9el4+WXVPfaISvjDh5dOs+uudk9VK+mHf6Ywcz/wQNWlS6P0t90WpfnlLy2znDvXMrewtLZmjS3HjInSvvKK7bv+ehOPe+9VHTTIjh10kOpLL0UZTFkMG2bnDB5smSKoXnllYuaWXPIdM0Z19uzSohba9/TTJkYDBybea9Ei89Batzax7NnT9oeeVoMGZvPpp1sJfv581RdfVN2bz/U0Rum3tLOSO5frZHrqvfwmwYNK/vTrF60ff7wtV60ysY+nO+UUs+uSS0wkCgvtO9pvPztWVGTp7rknepaXXkq8Rt26ljGCZdKgOmRIJFLffGPnPfSQbS9ZEr378eMtww7PLyxU/eorW+/c2TJ+UP3rXyM7RFR/9zvVBQss/eWXR7Z98kl0v1tuSf1umje39/3rX1u6tWvtnYPqVVfZfY8/3p7rttvsmuG5oZcFqrMKeyReOOapZYoLgZM1HnzQSl+XXGIZY1USZjAjR5Y+dsIJlpGqRqX5MPPcvLl0+uefj9KEf950xEuhK1dG+0PB+PRTC0fEj5VHcbGFsuL/5ccei9aXLIlKot99Z6X8M86wsFNyibKoyDKo5s1t+fnnqZ+hYUM7N/QmHnzQtjt0sO1Ro2x7770jO+7kTi1BtJD12pVpKTO38DNjhuqXX6qedVa0Lzls1LRptH777Rbm6to1Cpvce6+t33yz2bTHHna93/5W9b33zBsEC+2BCXIoZuG7efvtKOT46quW2f7mN+aFlZRYSK5ePfOyQhHo29eWoWCIqP7hD7a+YIGJaPh9vf662faLX9g7XbbMfpOhVxeK1amnRs8av88pp5g3VlJiodNwfxgqu/9+86jOP9/CmQ0bRs8bfp7h56W/gPbtM/8BqguBkwPWrq1YxpgJM2aYuMTDUSHFxVFJPCxJQupMUdUyrLAgVV4J/rvvoutVJffdFwnAo4+a9/SHP6h+9pkdX7xY9YcfbP3WWy1tmzYWNtm0KfFa999vz9K/f/r7/f3vdo3XXrPt8eNt+9BDbbuoKMqQw8+oBueoQikROO44W4Zhj+bNo/tccUVMSO5MvN7BB0frH34YeUF166rutVcsowsKt2eeGYWeDjrIPLymTa3U3LCheapr1kS/ifHjTaDDZwMLNV1wQSR4qlHocI897JqjR2spb2bPPc3DVbUwT/i84b2mT7d9N99spfpQaEPPa+PGqK4mrGsYONDqFsA8jn79LNOfN8/CZGAFi2OOsWs0bWq2n3yyHdt1V9WGrNNreaC0EIhk+MszXAic7Z7wvxGvkI1TXGwZ5wEHlH+tTZvsWlX9U9u8WXXcuPQVh3HWr7eMAazknoo1a0oLRJytW01kwvtt2GCl5HPOidIcfrjd4+STLV/59q8jVdu319N50TLKfRbrli2WWYHq2Wfb8ic/ia4RhlIgKh2Hpd2BA6NjxcVm79NPW7gvHvaZOtWudffdiXld+/YW2nr7bav/SMecOdE5deqotmplmXnIY4/Z/rA+Z+VKE6M6dRLF8Je/jNKLqL71VuJ94uGasKI+fG7VKBx26aW2/P3v7V4FBVFI8P/9P0t75pmW0ZeUJHpSY8ZE7+GII1SPL3xXd2O+FlOn9MupANUmBMDxwJfAHODmFMcLgBHB8Y+BDuVd04XAScUnn1jYoKxM9rLLrASeCRMnJraYqg4WLbLwRybCkSl//7vq++9H2y+8oHrxxVbSDjNjVQutgFU2q1pmdfbZliF362YZXUhxsWXSl11m6ZYts9AORPUp6byrWbOs1U74jK+9Zml32y0qcd9+e/nPFfcK69e3z5Qp0fGSEtWFCxPPCUNafftaIaFu3agyeOtWe65kQvsOPti2e/VKrIgOnzsUx2eftf3h9m67Ra2iiorMM1CNPMBDDrF7v/OObV9yieoLg96zEBXHRw9ZW+oIgLrA10AnoAHwGbBvUpqrgCHB+nnAiPKu60LgONnnn/+03GHs2NLHli6NKtbTEYZeLrnE1surlwkJmwZfe63q//6XKFplsXWrnXfWWar/+IfVCZXHuHF2zhVXWOX1//1f+eeUlFj68L0sXmwtskKWLFEdOlT1668tBBQ+99at1lDgvfdSX/eDDyysFIY2i4osr3/wQfOiWu24QU9v+EbWWg2JHa96ROQQ4C5VPS7YviXot/DHWJo3gzTjRaQe8D3QSsswqlevXjopuUuk4zhVyrp11nnt4osTe0pnSkkJ/OUvNjx6cofA8hgxwjrPJfdcL481a6xPYnyq0LJQtY6GJ56YenDF6mbBAnsHDRrYyKpNm0ZDyVcGEZmsqr1SHsuiEJwFHK+qvwi2LwR6q+qvYmlmBGkWBttfB2mWJV3rMuAygN133/3A+dsyQa7jOE4eUpYQ1IohJlR1qKr2UtVercJ5HB3HcZwqIZtCsAjYLbbdLtiXMk0QGmoKpBh2y3Ecx8kW2RSCT4DOItJRRBpglcGvJKV5BRgQrJ8F/K+s+gHHcRyn6qmXrQurarGI/Ap4E2tB9ISqzhSRwVjt9SvAP4GnRWQOsAITC8dxHCeHZE0IAFT1deD1pH2/ja1vBM7Opg2O4zhO2dSKymLHcRwne7gQOI7j5DkuBI7jOHlO1jqUZQsRWQpUtkdZS2BZualqBrXFVrez6qkttrqdVUu27Wyvqik7YtU6IdgWRGRSup51NY3aYqvbWfXUFlvdzqqlOu300JDjOE6e40LgOI6T5+SbEAytbgMqQG2x1e2semqLrW5n1VJtduZVHYHjOI5TmnzzCBzHcZwkXAgcx3HynLwRAhE5XkS+FJE5InJzju65m4i8KyKfi8hMEbk22H+XiCwSkanB58TYObcENn4pIseVZ38wuuvHwf4RwUivlbF1nohMD+yZFOxrLiJvi8jsYLlTsF9E5KHgntNE5IDYdQYE6WeLyIDY/gOD688Jzq3wvFcislfsnU0VkdUicl1NeZ8i8oSI/BBMuBTuy/o7THePCtr5ZxH5IrBllIg0C/Z3EJENsXc7pLL2lPXMFbAz69+1iBQE23OC4x3KsrMMW0fE7JwnIlOr+52mJd0cltvThwzmT87SfVsDBwTrOwBfAfsCdwE3pEi/b2BbAdAxsLluWfYDzwPnBetDgCsraes8oGXSvj8BNwfrNwP3BesnAm8AAhwMfBzsbw7MDZY7Bes7BccmBmklOPeEKvhOvwfa15T3CRwOHADMyOU7THePCtp5LFAvWL8vZmeHeLqk61TInnTPXEE7s/5dU4m51FPZmnT8L8Bvq/udpvvki0dwEDBHVeeq6mbgOeC0bN9UVRer6pRgfQ0wC2hbximnAc+p6iZV/QaYg9me0v6gtHAU8EJw/r+An1XhI5wWXDP52qcBT6kxAWgmIq2B44C3VXWFqq4E3gaOD47tqKoT1H69T1WBnUcDX6tqWb3Mc/o+VfV9bDj1ZBuy/Q7T3SNjO1X1LVUtDjYnYBNJpaWS9qR75oztLIOq/K7j9r8AHB2WzCtja3DuOcC/y7pGLt5pOvJFCNoCC2LbCyk7Q65yAveyJ/BxsOtXgSv3RMyVT2dnuv0tgFWxP/C2PJcCb4nIZLE5ogF2UdXFwfr3QDideEXtbBusJ+/fFs4j8Y9V095nSC7eYbp7VJZLsFJmSEcR+VRE3hORvjH7K2pPVf0Ps/1d/3hOcLwoSF9Z+gJLVHV2bF+Neqf5IgTViog0AV4ErlPV1cCjwB5AD2Ax5jZWN4ep6gHACcDVInJ4/GBQQqkRbY2DWO6pwH+CXTXxfZYiF+9wW+8hIrcBxcDwYNdiYHdV7QlcDzwrIjvmyp4U1IrvOonzSSy01LR3mjdCkMn8yVlBROpjIjBcVUcCqOoSVS1R1a3APzD3tSw70+1fjrmC9ZL2VxhVXRQsfwBGBTYtCd3MYPlDJe1cRGKoYVvf/wnAFFVdEthc495njFy8w3T3qBAiMhA4GegfZDYEoZblwfpkLN7epZL2bPP/MEffdZXNpR6cfwYwIvYMNeqdQv4IQSbzJ1c5QWzwn8AsVb0/tj8ewzsdCFsavAKcF7Ra6Ah0xiqPUtof/FnfxeZ7Bpv/+eVK2NlYRHYI17GKwxkkzikdv/YrwEVBi4WDgaLAbX0TOFZEdgpc9mOBN4Njq0Xk4OCdXFQZO2MklLBq2vtMIhfvMN09MkZEjgduAk5V1fWx/a1EpG6w3gl7h3MraU+6Z66Inbn4rqtyLvVjgC9U9ceQT017p0B+tBrSqHb9K0x9b8vRPQ/DXLhpwNTgcyLwNDA92P8K0Dp2zm2BjV8Sa1mTzn6sNcRErHLsP0BBJezshLWm+AyYGV4fi4uOAWYD7wDNg/0C/C2wZTrQK3atSwJb5gAXx/b3wv60XwOPEPRqr4StjbHSWdPYvhrxPjFxWgxswWK1l+biHaa7RwXtnIPFmsPfadhq5szgNzEVmAKcUll7ynrmCtiZ9e8aKAy25wTHO1Xmuw/2DwOuSEpbbe803ceHmHAcx8lz8iU05DiO46TBhcBxHCfPcSFwHMfJc1wIHMdx8hwXAsdxnDzHhcCpckRkrIhkfRJuERkkIrNEZHjS/h4SG5WyAtdrIyIvZJDudQlG59weEJF+IvJaddvhVB/1yk/iOLlDROppNP5LeVwFHKOxzjoBPbD22K9X5Pqq+h1RB6O0qGqFRcZxajLuEeQpYmOizxKRf4jNlfCWiDQMjv1YoheRliIyL1gfKCIviY2HPk9EfiUi14sNnjVBRJrHbnGh2FjrM0TkoOD8xmIDhU0Mzjktdt1XROR/WKeZZFuvD64zQ0SuC/YNwToEvSEiv46lbQAMBs4N7n+u2Bj2T4vIh8DTwbOPE5EpwadP7J3MiNk0UkT+KzYG/J9i95gXvJey3uFPxAZGmyo21v+P49QnPduNIvJJkPZ3wb7TRWRM0Fu0tYh8JSK7lmF3P7HBy14Wkbkicq+I9A/e83QR2SNIN0xEhojIpOCaJ6ewJ913tF+wb2pga+ek8+oG158R3PPXwf49gnc4ObB972B/KxF5MXj2T0Tk0GD/XcH9xwbPMijVe3OqmMr0QvNP7f9gY6IXAz2C7eeBC4L1sQQ9FIGWwLxgfSDW23IHoBU2KuMVwbEHsEH1wvP/EawfTjD2OvCH2D2aYb09GwfXXUiKHrHAgViPycZAE6xHZs/g2DyS5lCI2flIbPsuYDLQMNhuBBQG652BSbF3MiN2jbnYODOFwHxgt/h9y3mHM4BDgvV7STH+PDZ8xFCsd2gd4DXg8ODYM8Cvgn3nl2N3P2AVNv9FATbWzO+CY9cCDwbrw4D/BvfqHLzzwuD818r5jh7GxiACG9e/YYrv6e3YdrNgOQboHKz3xoZrAHgWG+gQYHdsGJbwu/ooeI6WWC/y+tX9f9nePx4aym++UdWpwfpkLGMrj3fV5lZYIyJFwKvB/ulA91i6f4ON0y4iO4rF1I8FThWRG4I0hVgmAMEY/CnudxgwSlXXAYjISGxY308zsDXOK6q6IVivDzwiIj2AEmzAr1SMUdWi4L6fY5PgLEhKU+odBs+6g6qOD/Y/iw3mlsyxwSd8liZYBv0+cA0mJhNUNRxXqSy7P9FgjBkR+Rp4K9g/HTgylu55tQHbZovIXGDvFDal+o7GA7eJSDtgpCYOqQwmmp1E5GFgNDakeROgD/AfiYbzLwiWxwD7xvbvGKQHGK2qm4BNIvIDNuRycvjPqUJcCPKbTbH1EqBhsF5MFDYsLOOcrbHtrST+npLHLlGs5Humqn4ZPyAivYF1FbK84sSv/2tgCbA/9pwb05yT/H5S/V/SvcNMEOCPqvpYimPtsHe6i4jUCTLvsuzelu8l2aZS3xEwS0Q+Bk4CXheRy1X1fz9eRHWliOyPTaxzBTYRy3XYmP89UjxfHeBgVU1494EwZPLenSrE6wicVMzDXH3IoPI0DecCiMhh2IiIRdjImteI/DgPa88MrjMO+JmINBIbGfX0YF9ZrMHCV+loCiwOMtcLsekMqwxVXYV5TL2DXeelSfomcElYEhaRtiKys9jQxU9go6zOwsasryq7zxaROkG9QSdsgLZkm0p9R2KjZM5V1YewkS/j3h8i0hKoo6ovArdjU7SuBr4RkbODNBKIBZjHck3s/B6VeBaninAhcFLx/4ArReRTLE5bGTYG5w/BRo0E+D0W3pgmIjOD7TJRm+pzGDYK5MfA46paXljoXSzsMFVEzk1x/O/AABH5DAuNZMMbuRT4h9iE5Y2x+pQEVPUtLGw0XkSmY9Mi7gDcCoxT1Q8wEfiFiOxTRXZ/i73LN7D6nWRvKN13dA4wI3iertg0inHaAmOD488AtwT7+wOXBjbPJJoidhDQK6h4/hzzIpxqwkcfdZwsICJNVHVtsH4zNlzytdVs0zCsUrjcvhJOfuGxN8fJDieJyC3Yf2w+1grJcWok7hE4juPkOV5H4DiOk+e4EDiO4+Q5LgSO4zh5jguB4zhOnuNC4DiOk+f8f4Hcc+BcBxlPAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(train_counter, train_losses, color='blue')\n",
    "plt.scatter(test_counter[1:], test_losses, color='red')\n",
    "plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "plt.xlabel('number of training examples seen')\n",
    "plt.ylabel('negative log likelihood loss')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}